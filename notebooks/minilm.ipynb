{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f84981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "      <td>[flex, actionscript-3, air]</td>\n",
       "      <td>sqlstatement.execute() - multiple queries in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n",
       "      <td>[svn, tortoisesvn, branch, branching-and-merging]</td>\n",
       "      <td>good branching and merging tutorials for torto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n",
       "      <td>[sql, asp.net, sitemap]</td>\n",
       "      <td>asp.net site maps &lt;p&gt;has anyone got experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n",
       "      <td>[algorithm, language-agnostic, colors, color-s...</td>\n",
       "      <td>function for creating color wheels &lt;p&gt;this is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n",
       "      <td>[c#, .net, scripting, compiler-construction]</td>\n",
       "      <td>adding scripting functionality to .net applica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "1  Good branching and merging tutorials for Torto...   \n",
       "2                                  ASP.NET Site Maps   \n",
       "3                 Function for creating color wheels   \n",
       "4  Adding scripting functionality to .NET applica...   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>I've written a database generation script i...   \n",
       "1  <p>Are there any really good tutorials explain...   \n",
       "2  <p>Has anyone got experience creating <strong>...   \n",
       "3  <p>This is something I've pseudo-solved many t...   \n",
       "4  <p>I have a little game written in C#. It uses...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                        [flex, actionscript-3, air]   \n",
       "1  [svn, tortoisesvn, branch, branching-and-merging]   \n",
       "2                            [sql, asp.net, sitemap]   \n",
       "3  [algorithm, language-agnostic, colors, color-s...   \n",
       "4       [c#, .net, scripting, compiler-construction]   \n",
       "\n",
       "                                                text  \n",
       "0  sqlstatement.execute() - multiple queries in o...  \n",
       "1  good branching and merging tutorials for torto...  \n",
       "2  asp.net site maps <p>has anyone got experience...  \n",
       "3  function for creating color wheels <p>this is ...  \n",
       "4  adding scripting functionality to .net applica...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "questions_path = \"../data/Questions.csv\"\n",
    "tags_path = \"../data/Tags.csv\"\n",
    "\n",
    "questions_df = pd.read_csv(questions_path, encoding=\"ISO-8859-1\")\n",
    "tags_df = pd.read_csv(tags_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "tags_grouped = tags_df.groupby(\"Id\")[\"Tag\"].apply(list).reset_index()\n",
    "\n",
    "\n",
    "merged_df = pd.merge(questions_df, tags_grouped, on=\"Id\")\n",
    "merged_df = merged_df[[\"Title\", \"Body\", \"Tag\"]]\n",
    "merged_df.columns = [\"title\", \"body\", \"tags\"]\n",
    "\n",
    "\n",
    "merged_df[\"text\"] = (merged_df[\"title\"] + \" \" + merged_df[\"body\"]).astype(str).str.lower()\n",
    "\n",
    "\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acb69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri boyutu (filtrelenmiş): (1057478, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tags\n",
       "javascript    124155\n",
       "java          115212\n",
       "c#            101186\n",
       "php            98808\n",
       "android        90659\n",
       "jquery         78542\n",
       "python         64601\n",
       "html           58976\n",
       "c++            47591\n",
       "ios            47009\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "all_tags = [tag for tag_list in merged_df[\"tags\"] for tag in tag_list]\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "\n",
    "top_tags = [tag for tag, count in tag_counts.most_common(100)]\n",
    "\n",
    "\n",
    "filtered_df = merged_df.copy()\n",
    "filtered_df[\"tags\"] = filtered_df[\"tags\"].apply(lambda tag_list: [tag for tag in tag_list if tag in top_tags])\n",
    "\n",
    "\n",
    "filtered_df = filtered_df[filtered_df[\"tags\"].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"Veri boyutu (filtrelenmiş): {filtered_df.shape}\")\n",
    "filtered_df[\"tags\"].explode().value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29076fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = filtered_df.sample(n=1000, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dfd7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (1000, 100)\n",
      "Örnek etiket vektörü: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Etiket isimleri: ['.htaccess' '.net' 'ajax' 'algorithm' 'android' 'angularjs' 'apache'\n",
      " 'api' 'arrays' 'asp.net'] ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(sample_df[\"tags\"])\n",
    "\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "print(f\"Örnek etiket vektörü: {y[0]}\")\n",
    "print(f\"Etiket isimleri: {mlb.classes_[:10]} ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92498d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "\n",
    "class StackOverflowDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "texts = sample_df[\"text\"].tolist()\n",
    "dataset = StackOverflowDataset(texts, y, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = StackOverflowDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = StackOverflowDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "047701b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLMClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(self.dropout(cls_output))\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189568c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_labels = y.shape[1]\n",
    "model = MiniLMClassifier(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08217c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "        for batch in loop:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a4252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:22<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.0000\n",
      "Macro F1: 0.0000\n",
      "Hamming Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Alp\\Desktop\\Python\\stackml-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss\n",
    "\n",
    "def evaluate_model(model, dataloader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            preds = (preds > threshold).astype(int)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    y_true = np.vstack(all_labels)\n",
    "\n",
    "    print(f\"Micro F1: {f1_score(y_true, y_pred, average='micro'):.4f}\")\n",
    "    print(f\"Macro F1: {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"Hamming Loss: {hamming_loss(y_true, y_pred):.4f}\")\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "y_true, y_pred = evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daca5375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8e74eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:23<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.0309\n",
      "Macro F1: 0.0274\n",
      "Hamming Loss: 0.5332\n",
      "1 tahmini sayısı: 10662\n",
      "\n",
      "Threshold: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:24<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.0336\n",
      "Macro F1: 0.0326\n",
      "Hamming Loss: 0.9829\n",
      "1 tahmini sayısı: 20000\n",
      "\n",
      "Threshold: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:24<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.0336\n",
      "Macro F1: 0.0326\n",
      "Hamming Loss: 0.9829\n",
      "1 tahmini sayısı: 20000\n",
      "\n",
      "Threshold: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:26<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.0336\n",
      "Macro F1: 0.0326\n",
      "Hamming Loss: 0.9829\n",
      "1 tahmini sayısı: 20000\n",
      "\n",
      "Threshold: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 13/13 [00:22<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1: 0.0336\n",
      "Macro F1: 0.0326\n",
      "Hamming Loss: 0.9829\n",
      "1 tahmini sayısı: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [0.5, 0.3, 0.2, 0.1, 0.05]:\n",
    "    print(f\"\\nThreshold: {t}\")\n",
    "    _, y_pred = evaluate_model(model, test_loader, threshold=t)\n",
    "    print(\"1 tahmini sayısı:\", np.sum(y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (StackML)",
   "language": "python",
   "name": "stackml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
